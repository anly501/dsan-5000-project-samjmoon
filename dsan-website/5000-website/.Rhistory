df_links = read.csv("./data/links.csv")
names(df_links)[1] = "link_id"
df_payment_orders = read.csv("./data/payment_orders.csv")
names(df_payment_orders)[1] = "payment_order_id"
df_transactions = read.csv("./data/transactions.csv")
names(df_transactions)[1] = "transaction_id"
#account_id
analytical_df = data.frame(account_id = df_accounts$account_id)
head(analytical_df)
#district_name
accounts_districts = merge(df_accounts, df_districts, by = "district_id")
accounts_districts = accounts_districts %>% distinct(account_id, .keep_all = TRUE)
accounts_districts = accounts_districts[, c("account_id", "name")]
#merge analytical_df with accounts_districts to map district names with account_id
analytical_df = merge(analytical_df, accounts_districts, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "name"] = "district_name"
head(analytical_df)
#open_date, statement_frequency
#date and statement_frequency from df_accounts
analytical_df = cbind(analytical_df, open_date = df_accounts$date)
analytical_df = cbind(analytical_df, statement_frequency = df_accounts$statement_frequency)
head(analytical_df)
#num_customers
#create df for customer count per account_id and merge with analytical_df
count_customers = table(df_links$account_id)
count_customers_df = as.data.frame(count_customers)
colnames(count_customers_df) = c("account_id", "count")
head(count_customers_df)
analytical_df = merge(analytical_df, count_customers_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "count"] = "num_customers"
head(analytical_df)
#credit_cards
#count number of credit cards per account
#merge cards and links tables
merge_cards_link = merge(df_links, df_cards, by = "link_id", all.x = TRUE)
#check if credit card exists in each row of card_id
na_check = ifelse(is.na(merge_cards_link$card_id), 0, 1)
merge_cards_link$is_card = na_check
head(merge_cards_link)
#count number of cards per account aggregating by account_id and create a new df. then merge with analytical_df
cards_per_account = aggregate(is_card ~ account_id, data = merge_cards_link, FUN = sum)
cards_per_account = as.data.frame(cards_per_account)
head(cards_per_account)
analytical_df = merge(analytical_df, cards_per_account, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "is_card"] = "credit_cards"
head(analytical_df)
#loans, loan amount, loan payments, loan term, loan status, loan default
#create subset df from loans table and merge with analytical table
subset_loans = subset(df_loans, select = c("account_id", "loan_id", 'amount', 'payments', 'term', 'status', 'default'))
head(subset_loans)
analytical_df = merge(analytical_df, subset_loans, by = "account_id", all.x = TRUE)
head(analytical_df)
analytical_df = analytical_df %>%
rename(loan = loan_id, loan_amount = amount, loan_payments = payments, loan_term = term, loan_status = status, loan_default = default)
head(analytical_df)
#max_withdrawal
#filter for cash methods and debit types
subset_cash_withdrawal = subset(df_transactions, select = c("account_id", "method", 'amount', 'type'))
subset_cash_withdrawal = subset_cash_withdrawal %>%
filter(method == 'cash' & type == "debit")
head(subset_cash_withdrawal)
#create a max withdrawal df and merge with analytical df
max_withdrawal = aggregate(amount ~ account_id, data = subset_cash_withdrawal, FUN = max)
max_withdrawal_df = as.data.frame(max_withdrawal)
head(max_withdrawal)
analytical_df = merge(analytical_df, max_withdrawal, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "max_withdrawal"
head(analytical_df)
#min_withdrawal
#create a min withdrawal df and merge with analytical df
min_withdrawal = aggregate(amount ~ account_id, data = subset_cash_withdrawal, FUN = min)
min_withdrawal_df = as.data.frame(min_withdrawal)
head(min_withdrawal)
analytical_df = merge(analytical_df, min_withdrawal, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "min_withdrawal"
head(analytical_df)
#cc_payments
print(methods)
#filter for credit card method and sum payments for each  account using aggregate function. then merge with analytical df
subset_cc = subset(df_transactions, select = c("account_id", "method", 'amount'))
subset_cc = subset_cc %>%
filter(method == 'credit card')
head(subset_cc)
cc_payments = aggregate(amount ~ account_id, data = subset_cc, FUN = sum)
cc_payments_df = as.data.frame(cc_payments)
head(cc_payments_df)
analytical_df = merge(analytical_df, cc_payments_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "cc_payments"
head(analytical_df)
#max_balance
#create subset from transaction table and find max balance for each account using aggregate function
subset_balance = subset(df_transactions, select = c("account_id", "balance"))
max_bal = aggregate(balance ~ account_id, data = subset_balance, FUN = max)
max_bal_df = as.data.frame(max_bal)
analytical_df = merge(analytical_df, max_bal_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "balance"] = "max_balance"
head(analytical_df)
#min_balance
#find min balance for each account using aggregate function
min_bal = aggregate(balance ~ account_id, data = subset_balance, FUN = min)
min_bal_df = as.data.frame(min_bal)
analytical_df = merge(analytical_df, min_bal_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "balance"] = "min_balance"
head(analytical_df)
print(nrow(analytical_df))
#saving analytical df to csv
write.csv(analytical_df, file = "./codes-and-outputs/analytical_r.csv", row.names = FALSE)
setwd("/Users/samanthamoon/Desktop/DSAN 5000/HW-02/codes-and-outputs")
library(tidyverse)
# Read in loans.csv to df
df = read.csv("../data/loans.csv")
# View the first few rows of df
head(df)
#renaming the first column as loan_id
names(df)[1] = "loan_id"
head(df)
num_rows = nrow(df)
num_rows
num_cols = ncol(df)
num_cols
#melting feature columns
melted_df = df |> pivot_longer(
-c(loan_id, account_id, date, amount, payments),
names_to = "term_status",
values_to = "has_this_term_status"
)
head(melted_df)
#filtering out missing instances of term/status and splitting terms and status into different columns
melted_df = subset(melted_df, has_this_term_status != "-")
head(melted_df)
melted_df$term_status = substr(melted_df$term_status, 2, nchar(melted_df$term_status))
head(melted_df)
melted_df$status = sapply(strsplit(melted_df$term_status, "_"), `[`, 2)
melted_df$term_status = sapply(strsplit(melted_df$term_status, "_"), `[`, 1)
head(melted_df)
names(melted_df)[6] = "term"
head(melted_df)
# check if loan defaulted
melted_df$default = ifelse(melted_df$status == "B", "yes", "no")
head(melted_df)
# replace ABCD with 'current' or 'expired'
melted_df = melted_df %>%
mutate(status = case_when(
status == "A" ~ "expired",
status == "B" ~ "expired",
status == "C" ~ "current",
status == "D" ~ "current",
TRUE ~ status  # Keep the original value if no conditions match
))
head(melted_df)
#saving melted df to csv
write.csv(melted_df, file = "./codes-and-outputs/loans_r.csv", row.names = FALSE)
library(tidyverse)
# Read in loans.csv to df
df = read.csv("../data/loans.csv")
# View the first few rows of df
head(df)
#renaming the first column as loan_id
names(df)[1] = "loan_id"
head(df)
num_rows = nrow(df)
num_rows
num_cols = ncol(df)
num_cols
#melting feature columns
melted_df = df |> pivot_longer(
-c(loan_id, account_id, date, amount, payments),
names_to = "term_status",
values_to = "has_this_term_status"
)
head(melted_df)
#filtering out missing instances of term/status and splitting terms and status into different columns
melted_df = subset(melted_df, has_this_term_status != "-")
head(melted_df)
melted_df$term_status = substr(melted_df$term_status, 2, nchar(melted_df$term_status))
head(melted_df)
melted_df$status = sapply(strsplit(melted_df$term_status, "_"), `[`, 2)
melted_df$term_status = sapply(strsplit(melted_df$term_status, "_"), `[`, 1)
head(melted_df)
names(melted_df)[6] = "term"
head(melted_df)
# check if loan defaulted
melted_df$default = ifelse(melted_df$status == "B", "yes", "no")
head(melted_df)
# replace ABCD with 'current' or 'expired'
melted_df = melted_df %>%
mutate(status = case_when(
status == "A" ~ "expired",
status == "B" ~ "expired",
status == "C" ~ "current",
status == "D" ~ "current",
TRUE ~ status  # Keep the original value if no conditions match
))
head(melted_df)
#saving melted df to csv
write.csv(melted_df, file = "./loans_r.csv", row.names = FALSE)
library(tidyverse)
library(dplyr)
#reading in files and renaming first column
df_loans = read.csv("./loans_r.csv")
df_districts = read.csv(".//district_r.csv")
df_accounts = read.csv("../data/accounts.csv")
names(df_accounts)[1] = "account_id"
df_cards = read.csv("../data/cards.csv")
names(df_cards)[1] = "card_id"
df_clients = read.csv("../data/clients.csv")
names(df_clients)[1] = "client_id"
df_links = read.csv("../data/links.csv")
names(df_links)[1] = "link_id"
df_payment_orders = read.csv("../data/payment_orders.csv")
names(df_payment_orders)[1] = "payment_order_id"
df_transactions = read.csv("../data/transactions.csv")
names(df_transactions)[1] = "transaction_id"
#account_id
analytical_df = data.frame(account_id = df_accounts$account_id)
head(analytical_df)
#district_name
accounts_districts = merge(df_accounts, df_districts, by = "district_id")
accounts_districts = accounts_districts %>% distinct(account_id, .keep_all = TRUE)
accounts_districts = accounts_districts[, c("account_id", "name")]
#merge analytical_df with accounts_districts to map district names with account_id
analytical_df = merge(analytical_df, accounts_districts, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "name"] = "district_name"
head(analytical_df)
#open_date, statement_frequency
#date and statement_frequency from df_accounts
analytical_df = cbind(analytical_df, open_date = df_accounts$date)
analytical_df = cbind(analytical_df, statement_frequency = df_accounts$statement_frequency)
head(analytical_df)
#num_customers
#create df for customer count per account_id and merge with analytical_df
count_customers = table(df_links$account_id)
count_customers_df = as.data.frame(count_customers)
colnames(count_customers_df) = c("account_id", "count")
head(count_customers_df)
analytical_df = merge(analytical_df, count_customers_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "count"] = "num_customers"
head(analytical_df)
#credit_cards
#count number of credit cards per account
#merge cards and links tables
merge_cards_link = merge(df_links, df_cards, by = "link_id", all.x = TRUE)
#check if credit card exists in each row of card_id
na_check = ifelse(is.na(merge_cards_link$card_id), 0, 1)
merge_cards_link$is_card = na_check
head(merge_cards_link)
#count number of cards per account aggregating by account_id and create a new df. then merge with analytical_df
cards_per_account = aggregate(is_card ~ account_id, data = merge_cards_link, FUN = sum)
cards_per_account = as.data.frame(cards_per_account)
head(cards_per_account)
analytical_df = merge(analytical_df, cards_per_account, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "is_card"] = "credit_cards"
head(analytical_df)
#loans, loan amount, loan payments, loan term, loan status, loan default
#create subset df from loans table and merge with analytical table
subset_loans = subset(df_loans, select = c("account_id", "loan_id", 'amount', 'payments', 'term', 'status', 'default'))
head(subset_loans)
analytical_df = merge(analytical_df, subset_loans, by = "account_id", all.x = TRUE)
head(analytical_df)
analytical_df = analytical_df %>%
rename(loan = loan_id, loan_amount = amount, loan_payments = payments, loan_term = term, loan_status = status, loan_default = default)
head(analytical_df)
#max_withdrawal
#filter for cash methods and debit types
subset_cash_withdrawal = subset(df_transactions, select = c("account_id", "method", 'amount', 'type'))
subset_cash_withdrawal = subset_cash_withdrawal %>%
filter(method == 'cash' & type == "debit")
head(subset_cash_withdrawal)
#create a max withdrawal df and merge with analytical df
max_withdrawal = aggregate(amount ~ account_id, data = subset_cash_withdrawal, FUN = max)
max_withdrawal_df = as.data.frame(max_withdrawal)
head(max_withdrawal)
analytical_df = merge(analytical_df, max_withdrawal, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "max_withdrawal"
head(analytical_df)
#min_withdrawal
#create a min withdrawal df and merge with analytical df
min_withdrawal = aggregate(amount ~ account_id, data = subset_cash_withdrawal, FUN = min)
min_withdrawal_df = as.data.frame(min_withdrawal)
head(min_withdrawal)
analytical_df = merge(analytical_df, min_withdrawal, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "min_withdrawal"
head(analytical_df)
#cc_payments
print(methods)
#filter for credit card method and sum payments for each  account using aggregate function. then merge with analytical df
subset_cc = subset(df_transactions, select = c("account_id", "method", 'amount'))
subset_cc = subset_cc %>%
filter(method == 'credit card')
head(subset_cc)
cc_payments = aggregate(amount ~ account_id, data = subset_cc, FUN = sum)
cc_payments_df = as.data.frame(cc_payments)
head(cc_payments_df)
analytical_df = merge(analytical_df, cc_payments_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "amount"] = "cc_payments"
head(analytical_df)
#max_balance
#create subset from transaction table and find max balance for each account using aggregate function
subset_balance = subset(df_transactions, select = c("account_id", "balance"))
max_bal = aggregate(balance ~ account_id, data = subset_balance, FUN = max)
max_bal_df = as.data.frame(max_bal)
analytical_df = merge(analytical_df, max_bal_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "balance"] = "max_balance"
head(analytical_df)
#min_balance
#find min balance for each account using aggregate function
min_bal = aggregate(balance ~ account_id, data = subset_balance, FUN = min)
min_bal_df = as.data.frame(min_bal)
analytical_df = merge(analytical_df, min_bal_df, by = "account_id", all.x = TRUE)
colnames(analytical_df)[colnames(analytical_df) == "balance"] = "min_balance"
head(analytical_df)
print(nrow(analytical_df))
#saving analytical df to csv
write.csv(analytical_df, file = "./analytical_r.csv", row.names = FALSE)
#cleaning districts.csv
library(tidyverse)
#reading in districts.csv
df = read.csv("../data/districts.csv")
head(df)
#renaming the first column as district_id
names(df)[1] = "district_id"
head(df)
num_rows = nrow(df)
num_rows
num_cols = ncol(df)
num_cols
#applying melt function
melted_df = df |> pivot_longer(
-c(district_id, name, region, population, num_cities, urban_ratio, avg_salary, entrepreneur_1000),
names_to = "info sets",
values_to = "values"
)
head(melted_df)
#saving melted df to csv
write.csv(melted_df, file = "./district_r.csv", row.names = FALSE)
setwd("/Users/samanthamoon/Desktop/DSAN 5000/dsan-5000-project-samjmoon/dsan-website/5000-website")
#reading in files and renaming first column
hm_df = read.csv("./data-gathering/HM_Women_Clothing.csv")
head(hm_df)
#reading in HM Women's Clothing data set from Kaggle
fashion_products_df = read.csv("./data-gathering/fashion_products.csv")
head(fashion_products_df)
shein_df = read.csv("./data-gathering/shein_sample.csv")
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_rows = nrow(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
column_names <- colnames(shirts_w_df)
column_names
shirts_w_df = subset(shirts_w_df, select = -Product_Image)
head(shirts_w_df)
shirts_w_df = subset(shirts_w_df, select = -Product_Image, -Link)
shirts_w_df <- subset(shirts_w_df, select = -c(Link, Product_Image))
shirts_w_df <- subset(shirts_w_df, select = -c('Link', 'Product_Image'))
library(tidyverse)
library(dplyr)
#reading in HM Women's Clothing data set from Kaggle
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
column_names = colnames(shirts_w_df)
column_names
shirts_w_df <- subset(shirts_w_df, select = -c(Link, Product_Image))
head(shirts_w_df)
library(tidyverse)
library(dplyr)
#reading in HM Women's Clothing data set from Kaggle
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
column_names = colnames(shirts_w_df)
column_names
shirts_w_df <- subset(shirts_w_df, select = -c(X, Link, Product_Image))
head(shirts_w_df)
column_names
column_names = colnames(shirts_w_df)
column_names
#converting rupee to usd
shirts_w_df$Price = substr(shirts_w_df$Price, 2, nchar(shirts_w_df$Price))
head(shirts_w_df)
shirts_w_df$Price = trimws(shirts_w_df$Price, "left")
head(shirts_w_df)
shirts_w_df$Price = as.numeric(shirts_w_df$Price
shirts_w_df$Price = as.numeric(shirts_w_df$Price)
shirts_w_df$Price = as.numeric(shirts_w_df$Price)
inr_to_usd <- function(x) {
return(x * 0.012)
}
library(tidyverse)
library(dplyr)
#reading in HM Women's Clothing data set from Kaggle
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
shirts_w_df <- subset(shirts_w_df, select = -c(X, Link, Product_Image))
head(shirts_w_df)
column_names = colnames(shirts_w_df)
column_names
#converting rupee to usd
shirts_w_df$Price = substr(shirts_w_df$Price, 2, nchar(shirts_w_df$Price))
shirts_w_df$Price = trimws(shirts_w_df$Price, "left")
head(shirts_w_df)
shirts_w_df$Price = as.numeric(shirts_w_df$Price)
library(tidyverse)
library(dplyr)
#reading in HM Women's Clothing data set from Kaggle
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
shirts_w_df <- subset(shirts_w_df, select = -c(X, Link, Product_Image))
head(shirts_w_df)
column_names = colnames(shirts_w_df)
column_names
#converting rupee to usd
shirts_w_df$Price = substr(shirts_w_df$Price, 2, nchar(shirts_w_df$Price))
shirts_w_df$Price = trimws(shirts_w_df$Price, "left")
shirts_w_df$Price = gsub(",", "", shirts_w_df$Price)
head(shirts_w_df)
library(tidyverse)
library(dplyr)
#reading in HM Women's Clothing data set from Kaggle
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
num_cols = ncol(shirts_w_df)
num_cols
num_rows = nrow(shirts_w_df)
num_rows
shirts_w_df <- subset(shirts_w_df, select = -c(X, Link, Product_Image))
head(shirts_w_df)
column_names = colnames(shirts_w_df)
column_names
#converting rupee to usd
shirts_w_df$Price = substr(shirts_w_df$Price, 2, nchar(shirts_w_df$Price))
shirts_w_df$Price = trimws(shirts_w_df$Price, "left")
shirts_w_df$Price = gsub(",", "", shirts_w_df$Price)
head(shirts_w_df)
shirts_w_df$Price = as.numeric(shirts_w_df$Price)
inr_to_usd <- function(x) {
return(x * 0.012)
}
shirts_w_df$Price = sapply(shirts_w_df$Price, inr_to_usd)
head(shirts_w_df)
#saving df to csv
write.csv(shirts_w_df, file = "./data-cleaning/cleaned_shirts_w.csv", row.names = FALSE)
library(tidyverse)
library(dplyr)
current_dir <- getwd()
print(current_dir)
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
column_names = colnames(shirts_w_df)
print(column_names)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(-X, -Link, -Product_Image)
library(tidyverse)
library(dplyr)
shirts_w_df = read.csv("./data-gathering/zara/Women/Women/SHIRTS.csv")
head(shirts_w_df)
column_names = colnames(shirts_w_df)
print(column_names)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(-X, -Link, -Product_Image)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(-'X', -'Link', -'Product_Image')
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(-X, -Link, -Product_Image)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(Product_Name, Price, Details)
#remove columns "X", "Link", "Product Image"
head(shirts_w_df)
shirts_w_df = shirts_w_df %>% select(-X)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df %>% select(-X)
#remove columns "X", "Link", "Product Image"
shirts_w_df <- shirts_w_df %>% select(-X)
shirts_w_df <- shirts_w_df %>%
select(-X, -Link, -Product_Image)
#remove columns "X", "Link", "Product Image"
shirts_w_df = shirts_w_df[, !names(shirts_w_df) %in% c("X", "Link", "Product_Image")]
head(shirts_w_df)
column_names = colnames(shirts_w_df)
print(column_names)
shirts_w_df$Price = substr(shirts_w_df$Price, 2, nchar(shirts_w_df$Price))
head(shirts_w_df)
shirts_w_df$Price = trimws(shirts_w_df$Price, "left")
head(shirts_w_df)
shirts_w_df$Price = gsub(",", "", shirts_w_df$Price)
head(shirts_w_df)
shirts_w_df$Price = as.numeric(shirts_w_df$Price)
inr_to_usd = function(x) {
return(x * 0.012)
}
shirts_w_df$Price = sapply(shirts_w_df$Price, inr_to_usd)
head(shirts_w_df)
#write cleaned df to csv file
write.csv(shirts_w_df, file = "./data-cleaning/cleaned_shirts_w.csv", row.names = FALSE)
